{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a30da8f",
   "metadata": {},
   "source": [
    "## 0. Introduction\n",
    "\n",
    "In this notebook we're going to build and train a deep learning model \"from scratch\" -- by which I mean that we're not going to use any pre-built architecture, or optimizers, or data loading frameworks, etc.\n",
    "\n",
    "We'll be using Kaggle's Titanic competition in this notebook, because it's very small and simple, but also has displays many of the tricky real-life issues that we need to handle in most practical projects. (Note, however, that this competition is a small \"learner\" competition on Kaggle, so don't expect to actually see much benefits from using a neural net just yet; that will come once we try our some real competitions!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ec58f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path_data = Path('data')\n",
    "path_comp = Path('titanic')\n",
    "path = path_data / path_comp\n",
    "\n",
    "if not path.exists():\n",
    "    import zipfile, kaggle\n",
    "    kaggle.api.competition_download_cli(str(path_comp))\n",
    "    zipfile.ZipFile(f\"{path_comp}.zip\").extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adba0e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "np.printoptions(linewidth=140)\n",
    "torch.set_printoptions(linewidth=140, sci_mode=False, edgeitems=7)\n",
    "pd.set_option('display.width', 140)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce4dd5a",
   "metadata": {},
   "source": [
    "## 1. Cleaning the data\n",
    "\n",
    "This is a tabular data competition -- the data is in the form of a table. It's provided as a Comma Separated Values (CSV) file. We can open it using the pandas library, which will create a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "888f7f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch            Ticket  \\\n",
       "0              1         0       3                            Braund, Mr. Owen Harris    male  22.0      1      0         A/5 21171   \n",
       "1              2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0          PC 17599   \n",
       "2              3         1       3                             Heikkinen, Miss. Laina  female  26.0      0      0  STON/O2. 3101282   \n",
       "3              4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0            113803   \n",
       "4              5         0       3                           Allen, Mr. William Henry    male  35.0      0      0            373450   \n",
       "..           ...       ...     ...                                                ...     ...   ...    ...    ...               ...   \n",
       "886          887         0       2                              Montvila, Rev. Juozas    male  27.0      0      0            211536   \n",
       "887          888         1       1                       Graham, Miss. Margaret Edith  female  19.0      0      0            112053   \n",
       "888          889         0       3           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1      2        W./C. 6607   \n",
       "889          890         1       1                              Behr, Mr. Karl Howell    male  26.0      0      0            111369   \n",
       "890          891         0       3                                Dooley, Mr. Patrick    male  32.0      0      0            370376   \n",
       "\n",
       "        Fare Cabin Embarked  \n",
       "0     7.2500   NaN        S  \n",
       "1    71.2833   C85        C  \n",
       "2     7.9250   NaN        S  \n",
       "3    53.1000  C123        S  \n",
       "4     8.0500   NaN        S  \n",
       "..       ...   ...      ...  \n",
       "886  13.0000   NaN        S  \n",
       "887  30.0000   B42        S  \n",
       "888  23.4500   NaN        S  \n",
       "889  30.0000  C148        C  \n",
       "890   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4893776b",
   "metadata": {},
   "source": [
    "As we learned in the How does a neural net really work notebook, we going to want to multiply each column by some coefficients. But we can see in the Cabin column that there are NaN values, which is how Pandas refers to missing values. We can't multiply something by a missing value!\n",
    "\n",
    "Let's check which columns contain NaN values. Pandas' isna() function returns True (which is treated as 1 when used as a number) for NaN values, so we can just add them up for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a39d25f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf3428b",
   "metadata": {},
   "source": [
    "Notice that by default Pandas sums over columns.\n",
    "\n",
    "We'll need to replace the missing values with something. It doesn't generally matter too much what we choose. We'll use the most common value (the \"mode\"). We can use the mode function for that. One wrinkle is that it returns more than one row in the case of ties, so we just grab the first row with iloc[0]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "b72f140a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId                      1\n",
       "Survived                       0.0\n",
       "Pclass                         3.0\n",
       "Name           Abbing, Mr. Anthony\n",
       "Sex                           male\n",
       "Age                           24.0\n",
       "SibSp                          0.0\n",
       "Parch                          0.0\n",
       "Ticket                        1601\n",
       "Fare                          8.05\n",
       "Cabin                      B96 B98\n",
       "Embarked                         S\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modes = df.mode().iloc[0]\n",
    "modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "52e54443",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(modes, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517f848e",
   "metadata": {},
   "source": [
    "Here's how we get a quick summary of all the numeric columns in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "63d9de23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>28.566970</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.199572</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000\n",
       "mean    446.000000    0.383838    2.308642   28.566970    0.523008    0.381594   32.204208\n",
       "std     257.353842    0.486592    0.836071   13.199572    1.102743    0.806057   49.693429\n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%     223.500000    0.000000    2.000000   22.000000    0.000000    0.000000    7.910400\n",
       "50%     446.000000    0.000000    3.000000   24.000000    0.000000    0.000000   14.454200\n",
       "75%     668.500000    1.000000    3.000000   35.000000    1.000000    0.000000   31.000000\n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=(np.number))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3ddaba",
   "metadata": {},
   "source": [
    "We can see that Fare contains mainly values of around 0 to 30, but there's a few really big ones. This is very common with fields contain monetary values, and it can cause problems for our model, because once that column is multiplied by a coefficient later, the few rows with really big values will dominate the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "14ac4602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Fare'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51327ce",
   "metadata": {},
   "source": [
    "To fix this, the most common approach is to take the logarithm, which squishes the big numbers and makes the distribution more reasonable. Note, however, that there are zeros in the Fare column, and log(0) is infinite -- to fix this, we'll simply add 1 to all values first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "c330166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LogFare'] = np.log(df['Fare'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "91afef96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['LogFare'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9046b8",
   "metadata": {},
   "source": [
    "It looks from the describe() output like Pclass contains just 3 values, which we can confirm by looking at the Data Dictionary (which you should always study carefully for any project!) --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "1c8213dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pclasses = sorted(df.Pclass.unique())\n",
    "pclasses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32f8106",
   "metadata": {},
   "source": [
    "Here's how we get a quick summary of all the non-numeric columns in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "60eeffb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>347082</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>691</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name   Sex  Ticket    Cabin Embarked\n",
       "count                       891   891     891      891      891\n",
       "unique                      891     2     681      147        3\n",
       "top     Braund, Mr. Owen Harris  male  347082  B96 B98        S\n",
       "freq                          1   577       7      691      646"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=[object])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a55d986",
   "metadata": {},
   "source": [
    "Clearly we can't multiply strings like male or S by coefficients, so we need to replace those with numbers.\n",
    "\n",
    "We do that by creating new columns containing dummy variables. A dummy variable is a column that contains a 1 where a particular column contains a particular value, or a 0 otherwise. For instance, we could create a dummy variable for Sex='male', which would be a new column containing 1 for rows where Sex is 'male', and 0 for rows where it isn't.\n",
    "\n",
    "Pandas can create these automatically using get_dummies, which also remove the original columns. We'll create dummy variables for Pclass, even although it's numeric, since the numbers 1, 2, and 3 correspond to first, second, and third class cabins - not to counts or measures that make sense to multiply by. We'll also create dummies for Sex and Embarked since we'll want to use those as predictors in our model. On the other hand, Cabin, Name, and Ticket have too many unique values for it to make sense creating dummy variables for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "55bd5d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'LogFare', 'Sex_female', 'Sex_male',\n",
       "       'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=[\"Sex\",\"Pclass\",\"Embarked\"])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a5409a",
   "metadata": {},
   "source": [
    "We can see that 5 columns have been added to the end -- one for each of the possible values of each of the three columns we requested, and that those three requested columns have been removed.\n",
    "\n",
    "Here's what the first few rows of those newly added columns look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "58f804ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex_male  Sex_female  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  Embarked_S\n",
       "0      True       False     False     False      True       False       False        True\n",
       "1     False        True      True     False     False        True       False       False\n",
       "2     False        True     False     False      True       False       False        True\n",
       "3     False        True      True     False     False       False       False        True\n",
       "4      True       False     False     False      True       False       False        True"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "added_cols = ['Sex_male', 'Sex_female', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
    "df[added_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a872562",
   "metadata": {},
   "source": [
    "Now we can create our independent (predictors) and dependent (target) variables. They both need to be PyTorch tensors. Our dependent variable is Survived:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "499702b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "\n",
    "t_dep = tensor(df.Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484a76c2",
   "metadata": {},
   "source": [
    "Our independent variables are all the continuous variables of interest plus all the dummy variables we just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "2ceeaf65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indep_cols = ['Age', 'SibSp', 'Parch', 'LogFare'] + added_cols\n",
    "t_indep = tensor(df[indep_cols].astype(np.float32).values)\n",
    "t_indep.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "0969c0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([891, 12])"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e98e5a",
   "metadata": {},
   "source": [
    "## 2. Setting up a linear model\n",
    "\n",
    "Now that we've got a matrix of independent variables and a dependent variable vector, we can work on calculating our predictions and our loss. In this section, we're going to manually do a single step of calculating predictions and loss for every row of our data.\n",
    "\n",
    "Our first model will be a simple linear model. We'll need a coefficient for each column in t_indep. We'll pick random numbers in the range (-0.5,0.5), and set our manual seed so that my explanations in the prose in this notebook will be consistent with what you see when you run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "d4c2a959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     0.2124,     -0.3234,     -0.1986,      0.1020,     -0.0053,     -0.3298,     -0.4567,      0.2992,     -0.0002,      0.0430,\n",
       "             0.4079,      0.2971])"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_coeff = t_indep.shape[1]\n",
    "coeffs = torch.rand(n_coeff) - 0.5\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613e79e2",
   "metadata": {},
   "source": [
    "Our predictions will be calculated by multiplying each row by the coefficients, and adding them up. One interesting point here is that we don't need a separate constant term (also known as a \"bias\" or \"intercept\" term), or a column of all 1s to give the same effect has having a constant term. That's because our dummy variables already cover the entire dataset -- e.g. there's a column for \"male\" and a column for \"female\", and everyone in the dataset is in exactly one of these; therefore, we don't need a separate intercept term to cover rows that aren't otherwise part of a column.\n",
    "\n",
    "Here's what the multiplication looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "75e6d0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     4.6719,     -0.3234,     -0.0000,      0.2152,     -0.0053,     -0.0000,     -0.0000,      0.0000,     -0.0002,      0.0000,\n",
       "              0.0000,      0.2971],\n",
       "        [     8.0696,     -0.3234,     -0.0000,      0.4366,     -0.0000,     -0.3298,     -0.4567,      0.0000,     -0.0000,      0.0430,\n",
       "              0.0000,      0.0000],\n",
       "        [     5.5213,     -0.0000,     -0.0000,      0.2232,     -0.0000,     -0.3298,     -0.0000,      0.0000,     -0.0002,      0.0000,\n",
       "              0.0000,      0.2971],\n",
       "        [     7.4326,     -0.3234,     -0.0000,      0.4070,     -0.0000,     -0.3298,     -0.4567,      0.0000,     -0.0000,      0.0000,\n",
       "              0.0000,      0.2971],\n",
       "        [     7.4326,     -0.0000,     -0.0000,      0.2247,     -0.0053,     -0.0000,     -0.0000,      0.0000,     -0.0002,      0.0000,\n",
       "              0.0000,      0.2971],\n",
       "        [     5.0966,     -0.0000,     -0.0000,      0.2292,     -0.0053,     -0.0000,     -0.0000,      0.0000,     -0.0002,      0.0000,\n",
       "              0.4079,      0.0000],\n",
       "        [    11.4674,     -0.0000,     -0.0000,      0.4047,     -0.0053,     -0.0000,     -0.4567,      0.0000,     -0.0000,      0.0000,\n",
       "              0.0000,      0.2971],\n",
       "        ...,\n",
       "        [     5.3090,     -0.0000,     -0.0000,      0.2127,     -0.0053,     -0.0000,     -0.0000,      0.0000,     -0.0002,      0.0000,\n",
       "              0.0000,      0.2971],\n",
       "        [     8.2820,     -0.0000,     -0.9928,      0.3473,     -0.0000,     -0.3298,     -0.0000,      0.0000,     -0.0002,      0.0000,\n",
       "              0.4079,      0.0000],\n",
       "        [     5.7337,     -0.0000,     -0.0000,      0.2692,     -0.0053,     -0.0000,     -0.0000,      0.2992,     -0.0000,      0.0000,\n",
       "              0.0000,      0.2971],\n",
       "        [     4.0348,     -0.0000,     -0.0000,      0.3502,     -0.0000,     -0.3298,     -0.4567,      0.0000,     -0.0000,      0.0000,\n",
       "              0.0000,      0.2971],\n",
       "        [     5.0966,     -0.3234,     -0.3971,      0.3260,     -0.0000,     -0.3298,     -0.0000,      0.0000,     -0.0002,      0.0000,\n",
       "              0.0000,      0.2971],\n",
       "        [     5.5213,     -0.0000,     -0.0000,      0.3502,     -0.0053,     -0.0000,     -0.4567,      0.0000,     -0.0000,      0.0430,\n",
       "              0.0000,      0.0000],\n",
       "        [     6.7955,     -0.0000,     -0.0000,      0.2212,     -0.0053,     -0.0000,     -0.0000,      0.0000,     -0.0002,      0.0000,\n",
       "              0.4079,      0.0000]])"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep*coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4f0517",
   "metadata": {},
   "source": [
    "We can see we've got a problem here. The sums of each row will be dominated by the first column, which is Age, since that's bigger on average than all the others.\n",
    "\n",
    "Let's make all the columns contain numbers from 0 to 1, by dividing each column by its max():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "c1dd32db",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, indices = t_indep.max(dim=0)\n",
    "t_indep /= vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "8531db7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3440, -0.6131,  0.0719, -0.3717,  0.4204,  0.5028,  0.0433,  0.1930,  0.0133,  0.0652])"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = (t_indep*coeffs).sum(axis=1)\n",
    "preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6050f7d2",
   "metadata": {},
   "source": [
    "Of course, these predictions aren't going to be any use, since our coefficients are random -- they're just a starting point for our gradient descent process.\n",
    "\n",
    "To do gradient descent, we need a loss function. Taking the average error of the rows (i.e. the absolute value of the difference between the prediction and the dependent) is generally a reasonable approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "23476f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5974)"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.abs(preds - t_dep).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "26560227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(coeffs, indeps): return (indeps * coeffs).sum(axis=1)\n",
    "def calc_loss(coeffs, indeps, deps): return torch.abs(calc_preds(coeffs, indeps) - deps).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba24cb8a",
   "metadata": {},
   "source": [
    "## 3. Doing a gradient descent step\n",
    "\n",
    "In this section, we're going to do a single \"epoch\" of gradient descent manually. The only thing we're going to automate is calculating gradients, because let's face it that's pretty tedious and entirely pointless to do by hand! To get PyTorch to calculate gradients, we'll need to call requires_grad_() on our coeffs (if you're not sure why, review the previous notebook, How does a neural net really work?, before continuing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "b8bd44f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     0.2124,     -0.3234,     -0.1986,      0.1020,     -0.0053,     -0.3298,     -0.4567,      0.2992,     -0.0002,      0.0430,\n",
       "             0.4079,      0.2971], requires_grad=True)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs.requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2285365b",
   "metadata": {},
   "source": [
    "Now when we calculate our loss, PyTorch will keep track of all the steps, so we'll be able to get the gradients afterwards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "93f735a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5974, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = calc_loss(coeffs, t_indep, t_dep)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "d988857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "c24487c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0141, -0.0081, -0.0277, -0.0611,  0.2750, -0.2536, -0.1975,  0.0112,  0.2076, -0.0965,  0.0191,  0.0988])"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40e1ba8",
   "metadata": {},
   "source": [
    "Note that each time we call backward, the gradients are actually added to whatever is in the .grad attribute. Let's try running the above steps again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "ed4dde92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0282, -0.0163, -0.0554, -0.1221,  0.5499, -0.5073, -0.3951,  0.0224,  0.4153, -0.1930,  0.0382,  0.1975])"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = calc_loss(coeffs, t_indep, t_dep)\n",
    "loss.backward()\n",
    "coeffs.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419b38c7",
   "metadata": {},
   "source": [
    "As you see, our .grad values are have doubled. That's because it added the gradients a second time. For this reason, after we use the gradients to do a gradient descent step, we need to set them back to zero.\n",
    "\n",
    "We can now do one gradient descent step, and check that our loss decreases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "dc9842eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5261)\n"
     ]
    }
   ],
   "source": [
    "loss = calc_loss(coeffs, t_indep, t_dep)\n",
    "loss.backward()\n",
    "with torch.inference_mode():\n",
    "    coeffs.sub_(coeffs.grad * 0.1)\n",
    "    coeffs.grad.zero_()\n",
    "    print(calc_loss(coeffs, t_indep, t_dep))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe025a2",
   "metadata": {},
   "source": [
    "## 4. Training the linear model\n",
    "\n",
    "Before we begin training our model, we'll need to ensure that we hold out a validation set for calculating our metrics (for details on this, see \"Getting started with NLP for absolute beginners\".\n",
    "\n",
    "There's lots of different ways we can do this. In the next notebook we'll be comparing our approach here to what the fastai library does, so we'll want to ensure we split the data in the same way. So let's use RandomSplitter to get indices that will split our data into training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "547cd58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.transforms import RandomSplitter\n",
    "trn_split, val_split = RandomSplitter()(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fff080a",
   "metadata": {},
   "source": [
    "Now we can apply those indices to our independent and dependent variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "9ce99954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713, 178)"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_indep, val_indep = t_indep[trn_split], t_indep[val_split]\n",
    "trn_dep, val_dep = t_dep[trn_split], t_dep[val_split]\n",
    "len(trn_dep), len(val_dep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3d02ba",
   "metadata": {},
   "source": [
    "We'll create functions for the three things we did manually above: updating coeffs, doing one full gradient descent step, and initilising coeffs to random numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "c2182a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coeffs(coeffs, lr):\n",
    "    coeffs.sub_(coeffs.grad * lr)\n",
    "    coeffs.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "9c29d47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch(coeffs, lr):\n",
    "    loss = calc_loss(coeffs, trn_indep, trn_dep)\n",
    "    loss.backward()\n",
    "    with torch.inference_mode(): update_coeffs(coeffs, lr)\n",
    "    print(f\"{loss:.3f}\", end=\"; \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "6739742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs():\n",
    "    return (torch.rand(n_coeff) - 0.5).requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07e4d9f",
   "metadata": {},
   "source": [
    "We can now use these functions to train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "c0a52f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs = 30, lr = 0.01):\n",
    "    coeffs = init_coeffs()\n",
    "    for i in range(epochs): one_epoch(coeffs, lr)\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "16f5009b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.124; 0.757; 0.502; 0.460; 0.422; 0.405; 0.391; 0.385; 0.361; 0.362; 0.344; 0.339; 0.328; 0.318; 0.311; 0.300; 0.296; 0.290; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(18, lr=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "a3d7af12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': tensor(-0.1450),\n",
       " 'SibSp': tensor(0.0206),\n",
       " 'Parch': tensor(-0.2640),\n",
       " 'LogFare': tensor(0.4684),\n",
       " 'Sex_male': tensor(-0.3077),\n",
       " 'Sex_female': tensor(0.3551),\n",
       " 'Pclass_1': tensor(0.3010),\n",
       " 'Pclass_2': tensor(0.3271),\n",
       " 'Pclass_3': tensor(0.0922),\n",
       " 'Embarked_C': tensor(0.0873),\n",
       " 'Embarked_Q': tensor(-0.0145),\n",
       " 'Embarked_S': tensor(-0.0171)}"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_coeffs(): return dict(zip(indep_cols, coeffs.requires_grad_(False)))\n",
    "show_coeffs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a54bee",
   "metadata": {},
   "source": [
    "## 5. Measuring accuracy\n",
    "\n",
    "The Kaggle competition is not, however, scored by absolute error (which is our loss function). It's scored by accuracy -- the proportion of rows where we correctly predict survival. Let's see how accurate we were on the validation set. First, calculate the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "8764b9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = calc_preds(coeffs, val_indep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f5949a",
   "metadata": {},
   "source": [
    "We'll assume that any passenger with a score of over 0.5 is predicted to survive. So that means we're correct for each row where preds>0.5 is the same as the dependent variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "462f1053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True, False,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = val_dep.bool() == (preds>0.5)\n",
    "results[:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6035d808",
   "metadata": {},
   "source": [
    "Let's see what our average accuracy is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "01c7eeb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8258)"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be79ce3",
   "metadata": {},
   "source": [
    "That's not a bad start at all! We'll create a function so we can calcuate the accuracy easy for other models we train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "3ec4c60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8258)"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def acc(coeffs): return (val_dep.bool() == (calc_preds(coeffs, val_indep) > 0.5)).float().mean()\n",
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b306292f",
   "metadata": {},
   "source": [
    "## 6. Using sigmoid\n",
    "\n",
    "Looking at our predictions, there's one obvious problem -- some of our predictions of the probability of survival are >1, and some are <0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "e4745172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3087,  0.3643, -0.1216,  0.5531, -0.0135, -0.1811,  0.2665,  0.5710, -0.1470, -0.1030, -0.1261,  0.1237,  0.9886,  1.0191,\n",
       "        -0.1084,  1.0599, -0.1086,  0.5963, -0.1263,  0.4931, -0.1093, -0.1068, -0.1043,  0.2876,  0.7828, -0.0970, -0.0411, -0.1123,\n",
       "         0.7980,  0.5455, -0.0604,  0.8483,  0.0208,  0.5144, -0.0893,  0.6096,  0.8391, -0.1139,  0.5519, -0.1201,  0.4806, -0.1406,\n",
       "         0.1128,  0.6991,  0.1222,  0.2303, -0.0386,  0.1128,  0.1580,  0.9073,  0.5987, -0.1155,  0.1331,  0.7943, -0.0063, -0.0899,\n",
       "         0.6024,  0.0101, -0.0077,  0.1204, -0.0986,  0.5487,  0.5707, -0.1126,  0.2913, -0.1480, -0.1152,  0.5533, -0.1193,  0.9629,\n",
       "         0.7974, -0.1109])"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[28:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "ca44d6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sympy as sp\n",
    "x = sp.Symbol('x')\n",
    "sp.plot(1/(1+sp.exp(-x)), xlim=(-5,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ea34e3",
   "metadata": {},
   "source": [
    "PyTorch already defines that function for us, so we can modify calc_preds to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "17d4d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(coeffs, indeps): return torch.sigmoid((indeps*coeffs).sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "9ea0106d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.522; 0.310; 0.214; 0.201; 0.194; 0.192; 0.190; 0.189; 0.189; 0.188; 0.188; 0.188; 0.187; 0.187; 0.187; 0.187; 0.187; 0.187; 0.187; 0.187; 0.186; 0.186; 0.186; 0.186; 0.186; 0.186; 0.186; 0.186; 0.186; 0.186; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "4b9c502a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7921)"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "407598bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': tensor(-1.1242),\n",
       " 'SibSp': tensor(-0.7366),\n",
       " 'Parch': tensor(-0.4432),\n",
       " 'LogFare': tensor(0.7788),\n",
       " 'Sex_male': tensor(-9.2367),\n",
       " 'Sex_female': tensor(7.9226),\n",
       " 'Pclass_1': tensor(2.8376),\n",
       " 'Pclass_2': tensor(2.5314),\n",
       " 'Pclass_3': tensor(-6.5389),\n",
       " 'Embarked_C': tensor(2.2859),\n",
       " 'Embarked_Q': tensor(2.6483),\n",
       " 'Embarked_S': tensor(-5.0586)}"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_coeffs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923abaf0",
   "metadata": {},
   "source": [
    "## 7. Submitting to Kaggle\n",
    "\n",
    "Now that we've got a trained model, we can prepare a submission to Kaggle. To do that, first we need to read the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "94e7832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df = pd.read_csv(path/'test.csv')\n",
    "tst_df['Fare'] = tst_df.Fare.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "c34e78a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df.fillna(modes, inplace=True)\n",
    "tst_df['LogFare'] = np.log(tst_df.Fare + 1)\n",
    "tst_df = pd.get_dummies(tst_df, columns=['Sex', 'Pclass', 'Embarked'])\n",
    "\n",
    "tst_indep = tensor(tst_df[indep_cols].astype(np.float32).values)\n",
    "tst_indep /= vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "15f11735",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df['Survived'] = (calc_preds(coeffs, tst_indep)>0.5).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "1e7275e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = tst_df[['PassengerId', 'Survived']]\n",
    "sub_df.to_csv('outputs/05_titanic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8412ab60",
   "metadata": {},
   "source": [
    "## 8. Using matrix product\n",
    "\n",
    "We can make things quite a bit neater...\n",
    "\n",
    "Take a look at the inner-most calculation we're doing to get the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "09cabf0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-13.1148, -20.8264,   5.7959, -21.1080, -13.6055,  -3.7303,   5.4983, -11.4788,   5.3774, -21.2314, -11.9088, -11.9530,   3.9654,\n",
       "        -11.3679, -12.0784,   3.9654,   3.3051, -11.8561, -11.7261,   5.3725,   3.5953, -20.9989, -20.8967,  -4.2125,  -3.7500, -20.8988,\n",
       "          5.5354,  12.6592,  -4.5000,  -4.0471, -21.0125,  -3.7134, -13.5640, -21.4000, -11.0832,  -3.7719, -21.1777, -20.8285, -21.0737,\n",
       "        -11.8309,   5.9627,  13.2396, -20.8707,  13.2222, -20.9484,  -3.9535, -21.0108,  -4.2657, -20.8721, -20.9343, -21.1007, -11.7474,\n",
       "          5.3004, -20.8518, -12.1011, -21.0066,   5.2404,  -3.7812, -20.9093,   5.5543, -20.7222,  -3.8013, -20.7049,  -3.7855,   5.3448,\n",
       "        -21.1388,   3.9651, -20.9564,  -3.8906, -13.4258, -11.9152,   3.5820, -11.9510, -11.6286, -13.6035, -11.9152, -11.6745,  12.7668,\n",
       "         -3.7781, -20.9045, -11.8666,   5.1908, -13.5078, -20.8179,  -3.8417, -20.8281, -13.5543, -11.9650, -20.8323,  -3.7207,   4.0958,\n",
       "        -13.2082,  -4.0501, -21.1794, -20.8820,  -3.7130, -20.9550,  12.6562,   5.4240, -13.1943, -12.0133, -20.8988,  13.1098,  -3.7681,\n",
       "        -20.8848, -11.4529,  12.9208,  -3.9094, -20.9113, -12.2593,  13.3331, -13.5359, -21.0196, -20.9790,  -3.7956,  12.8212, -21.0674,\n",
       "        -11.5370, -11.7606, -13.1940, -13.1943,   6.0610,  -4.0366,  -4.2364, -13.2074, -11.8774, -20.6940, -20.8967, -11.8561,  -4.1580,\n",
       "        -13.6807, -20.6659, -13.2430, -20.8967, -20.8988,   5.4051,  -3.8272, -13.1940, -20.9269,  -3.7618, -20.9129,   3.7724, -11.4313,\n",
       "        -11.4368, -11.8237, -20.9049, -20.9799, -11.5091,   5.0096, -21.2187,   3.8740, -20.8967, -21.0107, -20.8967,   5.2189, -20.9810,\n",
       "         13.0885,  13.0042, -20.8437, -20.9831, -11.9574,   4.9761, -21.5247,   5.1110,   6.0198, -20.9113, -20.9124, -11.4900, -11.6446,\n",
       "        -20.9279,   5.7560,   5.6362, -13.2059, -21.5247, -21.4102, -21.0607, -20.9116, -11.9990])"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(val_indep*coeffs).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982231b3",
   "metadata": {},
   "source": [
    "Multiplying elements together and then adding across rows is identical to doing a matrix-vector product! Python uses the @ operator to indicate matrix products, and is supported by PyTorch tensors. Therefore, we can replicate the above calculate more simply like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "bf0285f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-13.1148, -20.8264,   5.7959, -21.1080, -13.6055,  -3.7303,   5.4983, -11.4788,   5.3774, -21.2314, -11.9088, -11.9530,   3.9654,\n",
       "        -11.3679, -12.0784,   3.9654,   3.3051, -11.8561, -11.7261,   5.3725,   3.5953, -20.9989, -20.8967,  -4.2125,  -3.7500, -20.8988,\n",
       "          5.5354,  12.6592,  -4.5000,  -4.0471, -21.0125,  -3.7134, -13.5640, -21.4000, -11.0832,  -3.7719, -21.1777, -20.8285, -21.0737,\n",
       "        -11.8309,   5.9627,  13.2396, -20.8707,  13.2222, -20.9484,  -3.9535, -21.0108,  -4.2657, -20.8721, -20.9343, -21.1007, -11.7474,\n",
       "          5.3004, -20.8518, -12.1011, -21.0066,   5.2404,  -3.7812, -20.9093,   5.5543, -20.7222,  -3.8013, -20.7049,  -3.7855,   5.3448,\n",
       "        -21.1388,   3.9651, -20.9564,  -3.8906, -13.4258, -11.9152,   3.5820, -11.9510, -11.6286, -13.6035, -11.9152, -11.6745,  12.7668,\n",
       "         -3.7781, -20.9045, -11.8666,   5.1908, -13.5078, -20.8179,  -3.8417, -20.8281, -13.5543, -11.9650, -20.8323,  -3.7207,   4.0958,\n",
       "        -13.2082,  -4.0501, -21.1794, -20.8820,  -3.7130, -20.9550,  12.6562,   5.4240, -13.1943, -12.0133, -20.8988,  13.1098,  -3.7681,\n",
       "        -20.8848, -11.4529,  12.9208,  -3.9094, -20.9113, -12.2593,  13.3331, -13.5359, -21.0196, -20.9790,  -3.7956,  12.8212, -21.0674,\n",
       "        -11.5370, -11.7606, -13.1940, -13.1943,   6.0610,  -4.0366,  -4.2364, -13.2074, -11.8774, -20.6940, -20.8967, -11.8561,  -4.1580,\n",
       "        -13.6807, -20.6659, -13.2430, -20.8967, -20.8988,   5.4051,  -3.8272, -13.1940, -20.9269,  -3.7618, -20.9129,   3.7724, -11.4313,\n",
       "        -11.4368, -11.8237, -20.9049, -20.9799, -11.5091,   5.0096, -21.2187,   3.8740, -20.8967, -21.0107, -20.8967,   5.2189, -20.9810,\n",
       "         13.0885,  13.0042, -20.8437, -20.9831, -11.9574,   4.9761, -21.5247,   5.1110,   6.0198, -20.9113, -20.9124, -11.4900, -11.6446,\n",
       "        -20.9279,   5.7560,   5.6362, -13.2059, -21.5247, -21.4102, -21.0607, -20.9116, -11.9990])"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_indep@coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "43ee6a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(coeffs, indeps): return torch.sigmoid(indeps@coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc2acde",
   "metadata": {},
   "source": [
    "In order to do matrix-matrix products (which we'll need in the next section), we need to turn coeffs into a column vector (i.e. a matrix with a single column), which we can do by passing a second argument 1 to torch.rand(), indicating that we want our coefficients to have one column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "a029416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs(): return (torch.rand(n_coeff, 1) * 0.1).requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31192681",
   "metadata": {},
   "source": [
    "We'll also need to turn our dependent variable into a column vector, which we can do by indexing the column dimension with the special value None, which tells PyTorch to add a new dimension in this position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "cbd3b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dep = trn_dep[:, None]\n",
    "val_dep = val_dep[:, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a172576f",
   "metadata": {},
   "source": [
    "We can now train our model as before and confirm we get identical outputs...:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "c4a405aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.512; 0.316; 0.236; 0.199; 0.194; 0.191; 0.190; 0.189; 0.188; 0.188; 0.188; 0.187; 0.187; 0.187; 0.187; 0.187; 0.186; 0.186; 0.186; 0.186; 0.186; 0.186; 0.186; 0.186; 0.186; 0.186; 0.186; 0.186; 0.186; 0.186; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef2bf02",
   "metadata": {},
   "source": [
    "... and identical accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "9e644ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7921)"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878c358e",
   "metadata": {},
   "source": [
    "## 9. A neural network\n",
    "\n",
    "We've now got what we need to implement our neural network.\n",
    "\n",
    "First, we'll need to create coefficients for each of our layers. Our first set of coefficients will take our n_coeff inputs, and create n_hidden outputs. We can choose whatever n_hidden we like -- a higher number gives our network more flexibility, but makes it slower and harder to train. So we need a matrix of size n_coeff by n_hidden. We'll divide these coefficients by n_hidden so that when we sum them up in the next layer we'll end up with similar magnitude numbers to what we started with.\n",
    "\n",
    "Then our second layer will need to take the n_hidden inputs and create a single output, so that means we need a n_hidden by 1 matrix there. The second layer will also need a constant term added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "2c7cb6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs(n_hidden=20):\n",
    "    layer1 = (torch.rand(n_coeff, n_hidden) - 0.5) / n_hidden\n",
    "    layer2 = torch.rand(n_hidden, 1) - 0.3\n",
    "    const = torch.rand(1)[0]\n",
    "    return layer1.requires_grad_(), layer2.requires_grad_(), const.requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44555fb5",
   "metadata": {},
   "source": [
    "Now we have our coefficients, we can create our neural net. The key steps are the two matrix products, indeps@l1 and res@l2 (where res is the output of the first layer). The first layer output is passed to F.relu (that's our non-linearity), and the second is passed to torch.sigmoid as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "c7e5aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def calc_preds(coeffs, indeps):\n",
    "    l1, l2, const = coeffs\n",
    "    res = F.relu(indeps@l1)\n",
    "    res = res@l2 + const\n",
    "    return torch.sigmoid(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260cf457",
   "metadata": {},
   "source": [
    "Finally, now that we have more than one set of coefficients, we need to add a loop to update each one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "e868b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coeffs(coeffs, lr):\n",
    "    for layer in coeffs:\n",
    "        layer.sub_(layer.grad * lr)\n",
    "        layer.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "71344558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.528; 0.430; 0.306; 0.249; 0.240; 0.222; 0.203; 0.217; 0.200; 0.220; 0.186; 0.186; 0.186; 0.185; 0.185; 0.185; 0.185; 0.185; 0.185; 0.185; 0.185; 0.185; 0.184; 0.184; 0.184; 0.184; 0.184; 0.184; 0.184; 0.184; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9983b8c",
   "metadata": {},
   "source": [
    "It's looking good -- our loss is lower than before. Let's see if that translates to a better result on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "a394e106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7921)"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d489e2",
   "metadata": {},
   "source": [
    "In this case our neural net isn't showing better results than the linear model. That's not surprising; this dataset is very small and very simple, and isn't the kind of thing we'd expect to see neural networks excel at. Furthermore, our validation set is too small to reliably see much accuracy difference. But the key thing is that we now know exactly what a real neural net looks like!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765cbd63",
   "metadata": {},
   "source": [
    "## 10. Final thoughts\n",
    "\n",
    "The biggest differences in practical models to what we have above are:\n",
    "\n",
    "- How initialisation and normalisation is done to ensure the model trains correctly every time\n",
    "- Regularization (to avoid over-fitting)\n",
    "- Modifying the neural net itself to take advantage of knowledge of the problem domain\n",
    "- Doing gradient descent steps on smaller batches, rather than the whole dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
